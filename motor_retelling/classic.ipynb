{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def generate_nested_cv_folds(ids, labels, outer_n=5, inner_n=4, random_state=42, shuffle=True, verbose=True):\n",
    "    \"\"\" \n",
    "    Generates nested cross-validation folds with ID-label pairs.\n",
    "    \"\"\"\n",
    "    ids = np.array(ids)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Generating fold assignments...\")\n",
    "        print(f\"=== Nested CV ({outer_n}-outer, {inner_n}-inner) ===\")\n",
    "        print(f\"Random state: {random_state} | Shuffle: {shuffle}\\n\")\n",
    "        print(f\"HC: {(labels == 0).sum()}, PD: {(labels == 1).sum()}\")\n",
    "\n",
    "    folds = {}\n",
    "    outer_cv = StratifiedKFold(n_splits=outer_n, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    for outer_idx, (train_idx, test_idx) in enumerate(outer_cv.split(ids, labels), 1):\n",
    "        train_ids, test_ids = ids[train_idx], ids[test_idx]\n",
    "        train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Outer Fold {outer_idx}/{outer_n}\")\n",
    "            print(f\"Train: {len(train_ids)} | Test: {len(test_ids)}\\n\")\n",
    "\n",
    "        outer_fold = {\n",
    "            \"test\": {id_: int(label) for id_, label in zip(test_ids, test_labels)},\n",
    "            \"inner\": {}\n",
    "        }\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=inner_n, shuffle=shuffle, random_state=outer_idx)\n",
    "        for inner_idx, (inner_train_idx, val_idx) in enumerate(inner_cv.split(train_ids, train_labels), 1):\n",
    "            inner_train_ids = train_ids[inner_train_idx]\n",
    "            inner_train_labels = train_labels[inner_train_idx]\n",
    "            val_ids = train_ids[val_idx]\n",
    "            val_labels = train_labels[val_idx]\n",
    "\n",
    "            outer_fold[\"inner\"][inner_idx] = {\n",
    "                \"train\": {id_: int(label) for id_, label in zip(inner_train_ids, inner_train_labels)},\n",
    "                \"val\": {id_: int(label) for id_, label in zip(val_ids, val_labels)}\n",
    "            }\n",
    "\n",
    "        folds[outer_idx] = outer_fold\n",
    "\n",
    "    return folds\n",
    "\n",
    "def generate_folds_from_classes(metadata_file, class_pair, output_file, exclude_id=\"C037_BFL\"):\n",
    "    # Load metadata and exclude unwanted ID\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    metadata = metadata[metadata['ID'] != exclude_id]\n",
    "\n",
    "    # Filter only the desired class2 values\n",
    "    metadata = metadata[metadata['class2'].isin(class_pair)]\n",
    "\n",
    "    # Map the classes to 0 and 1\n",
    "    label_map = {class_pair[0]: 0, class_pair[1]: 1}\n",
    "    metadata['class2'] = metadata['class2'].map(label_map)\n",
    "\n",
    "    # Drop any rows with missing values\n",
    "    metadata = metadata.dropna()\n",
    "    metadata['class2'] = metadata['class2'].astype(int)\n",
    "\n",
    "    # Get ids and labels\n",
    "    ids = metadata['ID'].tolist()\n",
    "    labels = metadata['class2'].tolist()\n",
    "\n",
    "    # Generate nested folds\n",
    "    fold_dict = generate_nested_cv_folds(ids, labels, outer_n=5, inner_n=4, random_state=42, shuffle=True)\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(fold_dict, f, indent=4)\n",
    "\n",
    "    print(f\"Saved folds to {output_file}\")\n",
    "\n",
    "# Settings\n",
    "outer_n = 5\n",
    "inner_n = 4\n",
    "random_state = 42\n",
    "shuffle = True\n",
    "\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "metadata = metadata[metadata['ID'] != 'C037_BFL']\n",
    "ids = metadata['ID'].to_list()\n",
    "labels = metadata['class'].to_list() # 0 = HC, 1 = PD\n",
    "\n",
    "fold_dict = generate_nested_cv_folds(ids, labels, outer_n=5, inner_n=4, random_state=42, shuffle=True)\n",
    "\n",
    "import json\n",
    "with open(\"folds/PD_vs_HC_folds.json\", \"w\") as f:\n",
    "    json.dump(fold_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_folds_from_classes(\n",
    "    metadata_file='metadata.csv',\n",
    "    class_pair=['CTR_DCL', 'Park_DCL'],\n",
    "    output_file='folds/CTR_DCL_vs_Park_DCL_folds.json'\n",
    ")\n",
    "\n",
    "generate_folds_from_classes(\n",
    "    metadata_file='metadata.csv',\n",
    "    class_pair=['CTR_noDCL', 'Park_noDCL'],\n",
    "    output_file='folds/CTR_noDCL_vs_Park_noDCL_folds.json'\n",
    ")\n",
    "\n",
    "generate_folds_from_classes(\n",
    "    metadata_file='metadata.csv',\n",
    "    class_pair=['Park_noDCL', 'Park_DCL'],\n",
    "    output_file='folds/Park_noDCL_vs_Park_DCL_folds.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running nested-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, recall_score, precision_score\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"Calculate specificity (true negative rate)\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def train_inner_model(X_train, y_train, inner_folds, random_state):\n",
    "    \"\"\"Train model with inner CV grid search\"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(probability=True, random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'svm__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'svm__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'svm__kernel': ['rbf']\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=inner_folds,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'sensitivity': recall_score(y_test, y_pred),\n",
    "        'specificity': specificity_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'y_true': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba\n",
    "    }\n",
    "\n",
    "def plot_ROC_curve(all_y_true, all_y_proba, filename='roc_curve.png'):\n",
    "    \"\"\"Generate and save ROC curve\"\"\"\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_y_true, all_y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(all_y_true, all_y_pred, filename='confusion_matrix.png'):\n",
    "    \"\"\"Generate and save confusion matrix\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(confusion_matrix(all_y_true, all_y_pred), \n",
    "                annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['HC', 'PD'],\n",
    "                yticklabels=['HC', 'PD'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_probability_density(y_true, y_proba, filename='probability_density.png'):\n",
    "    \"\"\"\n",
    "    Plot density distribution of predicted probabilities for each class\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels (0=HC, 1=PD)\n",
    "    y_proba : array-like\n",
    "        Predicted probabilities for class 1 (PD)\n",
    "    save_path : str\n",
    "        Path to save the plot\n",
    "    \"\"\"\n",
    "    # Create DataFrame for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'Probability': y_proba,\n",
    "        'Group': ['HC' if label == 0 else 'PD' for label in y_true]\n",
    "    })\n",
    "    \n",
    "    # Define colors (Soft blue shades)\n",
    "    blues = sns.color_palette(\"Blues\", n_colors=6)\n",
    "    colors = [blues[1], blues[4]]  # light blue for HC, dark blue for PD\n",
    "\n",
    "    # Create figure with two subplots: Boxplot (top) and Density plot (bottom)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, gridspec_kw={'height_ratios': [1, 4]}, figsize=(6, 6), sharex=True)\n",
    "\n",
    "    # Boxplot (Top)\n",
    "    sns.boxplot(x=\"Probability\", y=\"Group\", data=df, hue=\"Group\", dodge=False, palette=colors, ax=axes[0], legend=False)\n",
    "    axes[0].set_xlabel(\"\")  # Remove xlabel to avoid redundancy\n",
    "    axes[0].set_ylabel(\"\")\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_title(\"Predicted Probability Distribution\")\n",
    "\n",
    "    # Histogram + KDE (Bottom)\n",
    "    sns.histplot(data=df, x=\"Probability\", hue=\"Group\", kde=True, palette=colors, stat=\"density\", bins=20, ax=axes[1], legend=True)\n",
    "    \n",
    "    axes[1].set_xlabel(\"Predicted Probability\")\n",
    "    legend_handles = [\n",
    "        Patch(color=colors[0], label='HC'),\n",
    "        Patch(color=colors[1], label='PD')\n",
    "    ]\n",
    "    axes[1].legend(handles=legend_handles)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)  # Save the plot\n",
    "    plt.close()\n",
    "\n",
    "def run_nested_svm_cv(fold_dict, features_df, random_state=42, features='articulation'):\n",
    "    \"\"\"\n",
    "        Perform nested CV SVM classification with predefined folds\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        fold_dict : dict\n",
    "            Output from generate_nested_cv_folds()\n",
    "        features_df : pd.DataFrame\n",
    "            DataFrame with features (index=filename, columns=features)\n",
    "        random_state : int\n",
    "            Random seed for reproducibility\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (results_df, all_y_true, all_y_pred, all_y_proba)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_proba = []\n",
    "\n",
    "    for outer_fold, fold_info in fold_dict.items():\n",
    "        test_ids = [id_ + '_MOTOR_LECTURA.wav' for id_ in fold_info[\"test\"].keys()]\n",
    "        y_test = list(fold_info[\"test\"].values())\n",
    "\n",
    "        train_labels_dict = {}\n",
    "        for inner in fold_info[\"inner\"].values():\n",
    "            train_labels_dict.update(inner[\"train\"])\n",
    "            train_labels_dict.update(inner[\"val\"])\n",
    "        train_ids = [id_ + '_MOTOR_LECTURA.wav' for id_ in train_labels_dict.keys()]\n",
    "        y_train = list(train_labels_dict.values())\n",
    "\n",
    "        X_train = features_df.loc[train_ids].values\n",
    "        X_test = features_df.loc[test_ids].values\n",
    "\n",
    "        inner_folds = []\n",
    "        for inner_num, inner in fold_info[\"inner\"].items():\n",
    "            inner_train_ids = [id_ + '_MOTOR_LECTURA.wav' for id_ in inner[\"train\"].keys()]\n",
    "            val_ids = [id_ + '_MOTOR_LECTURA.wav' for id_ in inner[\"val\"].keys()]\n",
    "            train_idx = [i for i, id_ in enumerate(train_ids) if id_ in inner_train_ids]\n",
    "            val_idx = [i for i, id_ in enumerate(train_ids) if id_ in val_ids]\n",
    "            inner_folds.append((train_idx, val_idx))\n",
    "\n",
    "        model = train_inner_model(X_train, y_train, inner_folds, random_state)\n",
    "        metrics = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "        results.append({\n",
    "            'outer_fold': outer_fold,\n",
    "            **metrics,\n",
    "            'best_params': model.get_params()['svm'],\n",
    "            'train_files': train_ids,\n",
    "            'test_files': test_ids\n",
    "        })\n",
    "\n",
    "        all_y_true.extend(metrics['y_true'])\n",
    "        all_y_pred.extend(metrics['y_pred'])\n",
    "        all_y_proba.extend(metrics['y_proba'])\n",
    "\n",
    "        print(f\"\\nFold {outer_fold} Results:\")\n",
    "        print(f\"Train set size: {len(y_train)}\")\n",
    "        print(f\"Test set size: {len(y_test)}\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "        print(f\"Sensitivity: {metrics['sensitivity']:.3f}\")\n",
    "        print(f\"Specificity: {metrics['specificity']:.3f}\")\n",
    "\n",
    "    plot_ROC_curve(all_y_true, all_y_proba, f'results/plots/roc_curve_{features}.png')\n",
    "    plot_confusion_matrix(all_y_true, all_y_pred, f'results/plots/confusion_matrix_{features}.png')\n",
    "    plot_probability_density(all_y_true, all_y_proba, f'results/plots/probability_density_{features}.png')\n",
    "\n",
    "    return results, np.array(all_y_true), np.array(all_y_pred), np.array(all_y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'articulation': ['articulationfeatures.csv'],\n",
    "    'phonation': ['phonationfeatures.csv'],\n",
    "    'phonological': ['phonologicalfeatures.csv'],\n",
    "    'prosody': ['prosodyfeatures.csv'],\n",
    "    'all': [\n",
    "        'articulationfeatures.csv',\n",
    "        'phonationfeatures.csv',\n",
    "        'phonologicalfeatures.csv',\n",
    "        'prosodyfeatures.csv'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"folds/PD_vs_HC_folds.json\", \"r\") as f:\n",
    "    fold_dict = json.load(f)\n",
    "\n",
    "# Loop over each feature set\n",
    "for feature_name, file_list in feature_sets.items():\n",
    "    print(f\"\\n=== Running Nested CV for: {feature_name} ===\")\n",
    "\n",
    "    # Load and combine features\n",
    "    features_df = pd.concat([\n",
    "        pd.read_csv(f'features/{f}').set_index('id') for f in file_list\n",
    "    ], axis=1)\n",
    "\n",
    "    print(f\"Feature shape: {features_df.shape}\")\n",
    "\n",
    "    # Run nested CV\n",
    "    results, _, _, _ = run_nested_svm_cv(fold_dict, features_df, features=feature_name)\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'results/{feature_name}_results.csv', index=False)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    final_metrics = {\n",
    "        'mean_accuracy': np.mean([x['accuracy'] for x in results]),\n",
    "        'std_accuracy': np.std([x['accuracy'] for x in results]),\n",
    "        'mean_sensitivity': np.mean([x['sensitivity'] for x in results]),\n",
    "        'std_sensitivity': np.std([x['sensitivity'] for x in results]),\n",
    "        'mean_specificity': np.mean([x['specificity'] for x in results]),\n",
    "        'std_specificity': np.std([x['specificity'] for x in results]),\n",
    "        'mean_f1': np.mean([x['f1'] for x in results]),\n",
    "        'std_f1': np.std([x['f1'] for x in results]),\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\n=== Final Metrics {feature_name.title()} ===\")\n",
    "    print(f\"Mean Accuracy: {100*final_metrics['mean_accuracy']:.1f} ± {100*final_metrics['std_accuracy']:.1f}\")\n",
    "    print(f\"Mean Sensitivity: {100*final_metrics['mean_sensitivity']:.1f} ± {100*final_metrics['std_sensitivity']:.1f}\")\n",
    "    print(f\"Mean Specificity: {100*final_metrics['mean_specificity']:.1f} ± {100*final_metrics['std_specificity']:.1f}\")\n",
    "    print(f\"Mean f1: {100*final_metrics['mean_f1']:.1f} ± {100*final_metrics['std_f1']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Nested CV for: articulation ===\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 1 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 2 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 3 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 4 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.250\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 5 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.667\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.750\n",
      "\n",
      "=== Final Metrics Articulation ===\n",
      "Mean Accuracy: 51.1 ± 8.2\n",
      "Mean Sensitivity: 84.0 ± 19.6\n",
      "Mean Specificity: 20.0 ± 29.2\n",
      "Mean f1: 63.2 ± 4.8\n",
      "\n",
      "=== Running Nested CV for: phonation ===\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 1 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 2 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 3 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.333\n",
      "Sensitivity: 0.250\n",
      "Specificity: 0.400\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 4 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.667\n",
      "Sensitivity: 0.800\n",
      "Specificity: 0.500\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 5 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.250\n",
      "\n",
      "=== Final Metrics Phonation ===\n",
      "Mean Accuracy: 48.9 ± 10.8\n",
      "Mean Sensitivity: 73.0 ± 28.2\n",
      "Mean Specificity: 23.0 ± 20.4\n",
      "Mean f1: 57.1 ± 17.1\n",
      "\n",
      "=== Running Nested CV for: phonological ===\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 1 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 2 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 3 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 4 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.667\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.750\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 5 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 0.400\n",
      "Specificity: 0.500\n",
      "\n",
      "=== Final Metrics Phonological ===\n",
      "Mean Accuracy: 51.1 ± 8.2\n",
      "Mean Sensitivity: 80.0 ± 25.3\n",
      "Mean Specificity: 25.0 ± 31.6\n",
      "Mean f1: 61.2 ± 8.6\n",
      "\n",
      "=== Running Nested CV for: prosody ===\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 1 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 2 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.700\n",
      "Sensitivity: 0.800\n",
      "Specificity: 0.600\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 3 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.667\n",
      "Sensitivity: 0.750\n",
      "Specificity: 0.600\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 4 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.556\n",
      "Sensitivity: 0.800\n",
      "Specificity: 0.250\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 5 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.250\n",
      "\n",
      "=== Final Metrics Prosody ===\n",
      "Mean Accuracy: 57.3 ± 9.7\n",
      "Mean Sensitivity: 79.0 ± 12.8\n",
      "Mean Specificity: 34.0 ± 23.1\n",
      "Mean f1: 65.5 ± 5.9\n",
      "\n",
      "=== Running Nested CV for: all ===\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 1 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 2 Results:\n",
      "Train set size: 37\n",
      "Test set size: 10\n",
      "Accuracy: 0.500\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 3 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 1.000\n",
      "Specificity: 0.000\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 4 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.556\n",
      "Sensitivity: 0.600\n",
      "Specificity: 0.500\n",
      "Fitting 4 folds for each of 49 candidates, totalling 196 fits\n",
      "\n",
      "Fold 5 Results:\n",
      "Train set size: 38\n",
      "Test set size: 9\n",
      "Accuracy: 0.444\n",
      "Sensitivity: 0.800\n",
      "Specificity: 0.000\n",
      "\n",
      "=== Final Metrics All ===\n",
      "Mean Accuracy: 48.9 ± 4.2\n",
      "Mean Sensitivity: 88.0 ± 16.0\n",
      "Mean Specificity: 10.0 ± 20.0\n",
      "Mean f1: 63.3 ± 2.8\n"
     ]
    }
   ],
   "source": [
    "feature_sets = {\n",
    "    'articulation': ['articulationfeatures.csv'],\n",
    "    'phonation': ['phonationfeatures.csv'],\n",
    "    'phonological': ['phonologicalfeatures.csv'],\n",
    "    'prosody': ['prosodyfeatures.csv'],\n",
    "    'all': [\n",
    "        'articulationfeatures.csv',\n",
    "        'phonationfeatures.csv',\n",
    "        'phonologicalfeatures.csv',\n",
    "        'prosodyfeatures.csv'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"folds/CTR_noDCL_vs_Park_noDCL_folds.json\", \"r\") as f:\n",
    "    fold_dict = json.load(f)\n",
    "\n",
    "# Loop over each feature set\n",
    "for feature_name, file_list in feature_sets.items():\n",
    "    print(f\"\\n=== Running Nested CV for: {feature_name} ===\")\n",
    "\n",
    "    # Load and combine features\n",
    "    features_df = pd.concat([\n",
    "        pd.read_csv(f'features/{f}').set_index('id') for f in file_list\n",
    "    ], axis=1)\n",
    "\n",
    "    # Run nested CV\n",
    "    results, _, _, _ = run_nested_svm_cv(fold_dict, features_df, features=feature_name)\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'results/{feature_name}_results.csv', index=False)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    final_metrics = {\n",
    "        'mean_accuracy': np.mean([x['accuracy'] for x in results]),\n",
    "        'std_accuracy': np.std([x['accuracy'] for x in results]),\n",
    "        'mean_sensitivity': np.mean([x['sensitivity'] for x in results]),\n",
    "        'std_sensitivity': np.std([x['sensitivity'] for x in results]),\n",
    "        'mean_specificity': np.mean([x['specificity'] for x in results]),\n",
    "        'std_specificity': np.std([x['specificity'] for x in results]),\n",
    "        'mean_f1': np.mean([x['f1'] for x in results]),\n",
    "        'std_f1': np.std([x['f1'] for x in results]),\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\n=== Final Metrics {feature_name.title()} ===\")\n",
    "    print(f\"Mean Accuracy: {100*final_metrics['mean_accuracy']:.1f} ± {100*final_metrics['std_accuracy']:.1f}\")\n",
    "    print(f\"Mean Sensitivity: {100*final_metrics['mean_sensitivity']:.1f} ± {100*final_metrics['std_sensitivity']:.1f}\")\n",
    "    print(f\"Mean Specificity: {100*final_metrics['mean_specificity']:.1f} ± {100*final_metrics['std_specificity']:.1f}\")\n",
    "    print(f\"Mean f1: {100*final_metrics['mean_f1']:.1f} ± {100*final_metrics['std_f1']:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
